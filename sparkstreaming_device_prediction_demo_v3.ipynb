{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# 1. Install PySpark\n",
        "!pip install pyspark findspark -q\n",
        "\n",
        "# 2. Initialize Spark Session with MEMORY LIMITS\n",
        "import findspark\n",
        "findspark.init()\n",
        "\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import udf, col, array\n",
        "from pyspark.sql.types import StructType, StructField, FloatType, IntegerType, ArrayType\n",
        "\n",
        "# Create a local Spark Session with explicit memory caps to prevent OOM\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"IoT_SmartHouse_Streaming\") \\\n",
        "    .master(\"local[2]\") \\\n",
        "    .config(\"spark.driver.memory\", \"2g\") \\\n",
        "    .config(\"spark.executor.memory\", \"2g\") \\\n",
        "    .config(\"spark.sql.shuffle.partitions\", \"2\") \\\n",
        "    .getOrCreate()\n",
        "\n",
        "print(\"Spark Session Created (Memory Optimized)\")\n"
      ],
      "metadata": {
        "id": "TR3NUbfouWyt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d63e753-1ded-4d41-9b34-cea54cc890d5"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Spark Session Created (Memory Optimized)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# This code loads the trained appliance prediction models and the scaler used during training.\n",
        "# The predict_appliances() function takes in temperature, time features, season, power, and encoded weather data.\n",
        "# It arranges these inputs in the exact order expected by the scaler, applies scaling, and then builds the final\n",
        "# feature vector for the models. Each of the five Random Forest models (one per appliance) then predicts whether\n",
        "# its appliance is ON or OFF. The function is finally registered as a Spark UDF so it can be used in DataFrame\n",
        "# operations to generate appliance state predictions.\n",
        "\n",
        "import pickle\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# 1. Load Models AND Scaler\n",
        "try:\n",
        "    with open('appliance_models.pkl', 'rb') as f:\n",
        "        rf_models = pickle.load(f)\n",
        "    print(\"Models loaded\")\n",
        "\n",
        "    with open('scaler.pkl', 'rb') as f:\n",
        "        scaler = pickle.load(f)\n",
        "    print(\"Scaler loaded\")\n",
        "\n",
        "    # DEBUG: Print scaler feature names to confirm order\n",
        "    if hasattr(scaler, 'feature_names_in_'):\n",
        "        print(f\"Scaler expects: {scaler.feature_names_in_}\")\n",
        "        SCALER_FEATURES = list(scaler.feature_names_in_)\n",
        "    else:\n",
        "        # Fallback if feature names not saved (older sklearn)\n",
        "        print(\"Scaler has no feature names. Assuming default order.\")\n",
        "        SCALER_FEATURES = ['Outside_Temperature_C', 'day_of_week', 'day_of_month', 'Apparent Power', 'hour_sin', 'hour_cos', 'month_sin', 'month_cos']\n",
        "\n",
        "except:\n",
        "    print(\"Models or Scaler not found. Prediction will be wrong!\")\n",
        "    SCALER_FEATURES = []\n",
        "\n",
        "# 2. Define UDF with Robust Scaling\n",
        "def predict_appliances(temp, hour_sin, hour_cos, month_sin, month_cos,\n",
        "                       day_of_week, season, time_of_day, day_of_month,\n",
        "                       apparent_power, weather_encoded_list):\n",
        "    try:\n",
        "        # Check inputs\n",
        "        if weather_encoded_list is None: return [-1] * 5\n",
        "\n",
        "        # --- A. PREPARE INPUT DICTIONARY ---\n",
        "        # Map all inputs to their names so we can pick them in the right order\n",
        "        input_map = {\n",
        "            'Outside_Temperature_C': float(temp),\n",
        "            'day_of_week': float(day_of_week),\n",
        "            'day_of_month': float(day_of_month),\n",
        "            'Apparent Power': float(apparent_power),\n",
        "            'hour_sin': float(hour_sin),\n",
        "            'hour_cos': float(hour_cos),\n",
        "            'month_sin': float(month_sin),\n",
        "            'month_cos': float(month_cos)\n",
        "        }\n",
        "\n",
        "        # --- B. CONSTRUCT RAW ROW FOR SCALER ---\n",
        "        # Pick values in the EXACT order the scaler learned\n",
        "        raw_row = []\n",
        "        for feature_name in SCALER_FEATURES:\n",
        "            # If feature matches one of our inputs, use it. Else 0.\n",
        "            val = input_map.get(feature_name, 0.0)\n",
        "            raw_row.append(val)\n",
        "\n",
        "        raw_nums = np.array([raw_row])\n",
        "\n",
        "        # --- C. SCALE ---\n",
        "        # This transforms raw values to scaled values\n",
        "        scaled_nums = scaler.transform(raw_nums)[0]\n",
        "\n",
        "        # --- D. MAP SCALED VALUES BACK ---\n",
        "        # Create a map of scaled values\n",
        "        scaled_map = dict(zip(SCALER_FEATURES, scaled_nums))\n",
        "\n",
        "        # Extract specific scaled values we need for the model feature vector\n",
        "        s_h_sin = scaled_map.get('hour_sin', hour_sin)\n",
        "        s_h_cos = scaled_map.get('hour_cos', hour_cos)\n",
        "        s_m_sin = scaled_map.get('month_sin', month_sin)\n",
        "        s_m_cos = scaled_map.get('month_cos', month_cos)\n",
        "        s_dow = scaled_map.get('day_of_week', day_of_week)\n",
        "        s_dom = scaled_map.get('day_of_month', day_of_month)\n",
        "        s_temp = scaled_map.get('Outside_Temperature_C', temp)\n",
        "        s_power = scaled_map.get('Apparent Power', apparent_power)\n",
        "\n",
        "        # --- E. CONSTRUCT MODEL FEATURE VECTOR ---\n",
        "        # Order: [hour_sin, hour_cos, month_sin, month_cos, day_of_week, season,\n",
        "        #         time_of_day, day_of_month, Outside_Temperature_C, ...weather..., Apparent Power]\n",
        "\n",
        "        features = [\n",
        "            s_h_sin, s_h_cos, s_m_sin, s_m_cos,\n",
        "            s_dow, season, time_of_day, s_dom,\n",
        "            s_temp,\n",
        "            *weather_encoded_list,\n",
        "            s_power\n",
        "        ]\n",
        "\n",
        "        # --- F. PREDICT ---\n",
        "        features_array = np.array(features).reshape(1, -1)\n",
        "        results = []\n",
        "        for device in ['Television', 'Dryer', 'Oven', 'Refrigerator', 'Microwave']:\n",
        "            model = rf_models[device]\n",
        "            pred = model.predict(features_array)[0]\n",
        "            results.append(int(pred))\n",
        "\n",
        "        return results\n",
        "\n",
        "    except Exception as e:\n",
        "        # print(str(e)) # Debug if needed\n",
        "        return [-1] * 5\n",
        "\n",
        "# Re-register UDF\n",
        "predict_udf = udf(predict_appliances, ArrayType(IntegerType()))\n",
        "print(\"UDF updated with ROBUST SCALING\")"
      ],
      "metadata": {
        "id": "aXShdxRVuXbI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "67ef57ba-ffd2-48c3-fd65-a56136b20d3f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Models loaded\n",
            "Scaler loaded\n",
            "Scaler expects: ['Outside_Temperature_C' 'hour_sin' 'hour_cos' 'month_sin' 'month_cos'\n",
            " 'day_of_week' 'day_of_month' 'Apparent Power']\n",
            "UDF updated with ROBUST SCALING\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# This script simulates a real-time data stream by repeatedly sampling small batches of rows\n",
        "# from a large smart-home dataset. For each batch, it recreates all feature engineering steps\n",
        "# used during model training, including cyclical time features, season/time-of-day encoding,\n",
        "# and one-hot weather encoding across 10 fixed weather columns. It then outputs each processed\n",
        "# batch as a CSV file into a streaming directory every few seconds, allowing Spark Structured\n",
        "# Streaming to read the data as if it were arriving in real time.\n",
        "\n",
        "import time\n",
        "import os\n",
        "import shutil\n",
        "import pandas as pd\n",
        "from threading import Thread\n",
        "\n",
        "# SETUP\n",
        "SOURCE_CSV_PATH = 'smart_home_dataset_with_weather.csv' # UPDATE THIS\n",
        "input_dir = \"/content/streaming_input\"\n",
        "\n",
        "if os.path.exists(input_dir):\n",
        "    shutil.rmtree(input_dir)\n",
        "os.makedirs(input_dir)\n",
        "\n",
        "def stream_data_generator():\n",
        "    print(f\"Simulator started using: {SOURCE_CSV_PATH}\")\n",
        "\n",
        "    # Load Data\n",
        "    try:\n",
        "        full_df = pd.read_csv(SOURCE_CSV_PATH)\n",
        "    except:\n",
        "        print(\"Error: CSV not found. Check path.\")\n",
        "        return\n",
        "\n",
        "    # THESE ARE THE 10 WEATHER COLUMNS YOUR MODEL EXPECTS\n",
        "    required_weather_cols = [\n",
        "        'weather_clear', 'weather_cloudy', 'weather_foggy', 'weather_overcast',\n",
        "        'weather_partly_cloudy', 'weather_rainy', 'weather_snowy', 'weather_sunny',\n",
        "        'weather_thunderstorm', 'weather_windy'\n",
        "    ]\n",
        "\n",
        "    batch_id = 0\n",
        "    while True:\n",
        "        try:\n",
        "            # Sample Data\n",
        "            raw_batch = full_df.sample(np.random.randint(5, 15)).copy()\n",
        "\n",
        "            # --- FEATURE ENGINEERING (Must match training exactly) ---\n",
        "            raw_batch['timestamp'] = pd.to_datetime(raw_batch['Unix Timestamp'], unit='s')\n",
        "            raw_batch['hour'] = raw_batch['timestamp'].dt.hour\n",
        "            raw_batch['month'] = raw_batch['timestamp'].dt.month\n",
        "\n",
        "            # 1. Cyclical\n",
        "            raw_batch['hour_sin'] = np.sin(2 * np.pi * raw_batch['hour'] / 24)\n",
        "            raw_batch['hour_cos'] = np.cos(2 * np.pi * raw_batch['hour'] / 24)\n",
        "            raw_batch['month_sin'] = np.sin(2 * np.pi * raw_batch['month'] / 12)\n",
        "            raw_batch['month_cos'] = np.cos(2 * np.pi * raw_batch['month'] / 12)\n",
        "\n",
        "            # 2. Categorical\n",
        "            raw_batch['day_of_week'] = raw_batch['timestamp'].dt.dayofweek\n",
        "            raw_batch['day_of_month'] = raw_batch['timestamp'].dt.day\n",
        "\n",
        "            # Season mapping\n",
        "            raw_batch['season'] = raw_batch['month'].apply(lambda m: 0 if m in [12,1,2] else 1 if m in [3,4,5] else 2 if m in [6,7,8] else 3)\n",
        "\n",
        "            # Time of Day mapping\n",
        "            raw_batch['time_of_day'] = raw_batch['hour'].apply(lambda h: 0 if 5<=h<12 else 1 if 12<=h<17 else 2 if 17<=h<21 else 3)\n",
        "\n",
        "            # 3. Weather Encoding (The Critical Fix)\n",
        "            # Create all 10 columns, initialized to 0\n",
        "            for col in required_weather_cols:\n",
        "                weather_type = col.replace('weather_', '')\n",
        "                # If the raw weather type matches, set to 1, else 0\n",
        "                raw_batch[col] = (raw_batch['Weather_Type'] == weather_type).astype(int)\n",
        "\n",
        "            # 4. Select Columns in EXACT ORDER\n",
        "            final_cols = [\n",
        "                'hour_sin', 'hour_cos', 'month_sin', 'month_cos',\n",
        "                'day_of_week', 'season', 'time_of_day', 'day_of_month',\n",
        "                'Outside_Temperature_C'\n",
        "            ] + required_weather_cols + ['Apparent Power']\n",
        "\n",
        "            output_df = raw_batch[final_cols]\n",
        "\n",
        "            # Write batch\n",
        "            output_df.to_csv(f\"{input_dir}/batch_{batch_id}.csv\", index=False)\n",
        "            batch_id += 1\n",
        "            time.sleep(3) # Slow down to prevent OOM\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Simulator Error: {e}\")\n",
        "            time.sleep(1)\n",
        "\n",
        "# Start Simulator\n",
        "t = Thread(target=stream_data_generator)\n",
        "t.daemon = True\n",
        "t.start()\n",
        "print(\"Simulator running...\")\n"
      ],
      "metadata": {
        "id": "wkTkCmoRuZ1V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3b57ba5a-df63-4843-c0f4-2abc2e0d9315"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Simulator started using: smart_home_dataset_with_weather.csv\n",
            "Simulator running...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# This code defines the schema for incoming streaming batches so it matches the exact\n",
        "# column structure produced by the simulator. It then reads CSV files as a Spark\n",
        "# Structured Stream, builds a weather feature array, and applies the custom prediction\n",
        "# UDF to generate ON/OFF predictions for five appliances. Finally, it selects the key\n",
        "# fields and starts an in-memory streaming query so predictions can be viewed\n",
        "# continuously as new batches arrive.\n",
        "\n",
        "# 1. Define Columns matching the simulator output\n",
        "weather_cols_names = [\n",
        "    'weather_clear', 'weather_cloudy', 'weather_foggy', 'weather_overcast',\n",
        "    'weather_partly_cloudy', 'weather_rainy', 'weather_snowy', 'weather_sunny',\n",
        "    'weather_thunderstorm', 'weather_windy'\n",
        "]\n",
        "\n",
        "stream_cols = [\n",
        "    'hour_sin', 'hour_cos', 'month_sin', 'month_cos',\n",
        "    'day_of_week', 'season', 'time_of_day', 'day_of_month',\n",
        "    'Outside_Temperature_C'\n",
        "] + weather_cols_names + ['Apparent Power']\n",
        "\n",
        "# 2. Create Schema\n",
        "schema = StructType([StructField(c, FloatType(), True) for c in stream_cols])\n",
        "\n",
        "# 3. Read Stream\n",
        "iot_stream = spark.readStream \\\n",
        "    .option(\"header\", \"true\") \\\n",
        "    .schema(schema) \\\n",
        "    .csv(input_dir)\n",
        "\n",
        "# 4. Transform & Predict\n",
        "weather_struct = [col(c) for c in weather_cols_names]\n",
        "\n",
        "predictions = iot_stream.withColumn(\n",
        "    \"weather_list\",\n",
        "    array(weather_struct)\n",
        ").withColumn(\n",
        "    \"pred\",\n",
        "    predict_udf(\n",
        "        col(\"Outside_Temperature_C\"),\n",
        "        col(\"hour_sin\"), col(\"hour_cos\"),\n",
        "        col(\"month_sin\"), col(\"month_cos\"),\n",
        "        col(\"day_of_week\"), col(\"season\"),\n",
        "        col(\"time_of_day\"), col(\"day_of_month\"),\n",
        "        col(\"Apparent Power\"),\n",
        "        col(\"weather_list\")\n",
        "    )\n",
        ")\n",
        "\n",
        "# 5. Select Output\n",
        "final_stream = predictions.select(\n",
        "    col(\"Outside_Temperature_C\").alias(\"Temp\"),\n",
        "    col(\"Apparent Power\").alias(\"Power\"),\n",
        "    col(\"pred\")[0].alias(\"TV\"),\n",
        "    col(\"pred\")[1].alias(\"Dryer\"),\n",
        "    col(\"pred\")[2].alias(\"Oven\"),\n",
        "    col(\"pred\")[3].alias(\"Fridge\"),\n",
        "    col(\"pred\")[4].alias(\"Micro\")\n",
        ")\n",
        "\n",
        "# 6. Start Query\n",
        "# Stop existing queries to free memory\n",
        "for q in spark.streams.active:\n",
        "    q.stop()\n",
        "\n",
        "query = final_stream.writeStream \\\n",
        "    .queryName(\"iot_predictions\") \\\n",
        "    .format(\"memory\") \\\n",
        "    .outputMode(\"append\") \\\n",
        "    .start()\n",
        "\n",
        "print(\"Streaming started.\")\n"
      ],
      "metadata": {
        "id": "nVQF1VQJyXF2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "99724f9b-e54a-461c-fa28-f39bc82c9f8c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Streaming started.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "from IPython.display import clear_output, display\n",
        "import pandas as pd\n",
        "\n",
        "start = time.time()\n",
        "last_count = 0\n",
        "\n",
        "print(\"Monitoring started... (Updates every 3s)\")\n",
        "\n",
        "while time.time() - start < 120:  # Run for 2 minutes\n",
        "    if spark.catalog.tableExists(\"iot_predictions\"):\n",
        "        # Get count to see if data is growing\n",
        "        count_df = spark.sql(\"SELECT count(*) as cnt FROM iot_predictions\").toPandas()\n",
        "        current_count = count_df['cnt'][0]\n",
        "\n",
        "        # Get latest 10 rows\n",
        "        df = spark.sql(\"SELECT * FROM iot_predictions\")\n",
        "        pdf = df.toPandas()\n",
        "\n",
        "        if current_count > last_count:\n",
        "            clear_output(wait=True)\n",
        "            print(f\"NEW BATCH RECEIVED! Total Rows: {current_count} (+{current_count - last_count})\")\n",
        "            print(f\"Time Elapsed: {int(time.time() - start)}s\")\n",
        "\n",
        "            # Show the last 10 rows (The newest batch)\n",
        "            display(pdf.tail(10))\n",
        "\n",
        "            last_count = current_count\n",
        "        else:\n",
        "            # Optional: Print dots to show it's alive\n",
        "            print(\".\", end=\"\", flush=True)\n",
        "\n",
        "    time.sleep(3)\n",
        "\n",
        "print(\"\\n Monitoring stopped.\")\n"
      ],
      "metadata": {
        "id": "iUFE3ICNQ5_M",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 432
        },
        "outputId": "83cd443f-237c-4f87-a149-27202df4b7b3"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NEW BATCH RECEIVED! Total Rows: 358 (+122)\n",
            "Time Elapsed: 132s\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "          Temp        Power  TV  Dryer  Oven  Fridge  Micro\n",
              "348  10.300000  2284.239014   1      1     1       1      1\n",
              "349  14.200000  1925.584717   0      0     0       1      0\n",
              "350  15.800000  1873.350586   0      0     0       1      0\n",
              "351  14.500000  1799.465942   0      0     0       0      0\n",
              "352  27.900000  1898.415283   0      0     0       1      0\n",
              "353  27.000000  1530.000000   0      0     0       0      0\n",
              "354   3.100000  2193.309570   1      1     1       1      1\n",
              "355  18.799999  1631.234009   0      0     1       0      0\n",
              "356  17.200001  1696.806763   0      0     0       0      0\n",
              "357  16.600000  1548.410400   0      1     0       0      1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-13517e96-de73-4a5c-b007-ece7b5f42d7b\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Temp</th>\n",
              "      <th>Power</th>\n",
              "      <th>TV</th>\n",
              "      <th>Dryer</th>\n",
              "      <th>Oven</th>\n",
              "      <th>Fridge</th>\n",
              "      <th>Micro</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>348</th>\n",
              "      <td>10.300000</td>\n",
              "      <td>2284.239014</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>349</th>\n",
              "      <td>14.200000</td>\n",
              "      <td>1925.584717</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>350</th>\n",
              "      <td>15.800000</td>\n",
              "      <td>1873.350586</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>351</th>\n",
              "      <td>14.500000</td>\n",
              "      <td>1799.465942</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>352</th>\n",
              "      <td>27.900000</td>\n",
              "      <td>1898.415283</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>353</th>\n",
              "      <td>27.000000</td>\n",
              "      <td>1530.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>354</th>\n",
              "      <td>3.100000</td>\n",
              "      <td>2193.309570</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>355</th>\n",
              "      <td>18.799999</td>\n",
              "      <td>1631.234009</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>356</th>\n",
              "      <td>17.200001</td>\n",
              "      <td>1696.806763</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>357</th>\n",
              "      <td>16.600000</td>\n",
              "      <td>1548.410400</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-13517e96-de73-4a5c-b007-ece7b5f42d7b')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-13517e96-de73-4a5c-b007-ece7b5f42d7b button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-13517e96-de73-4a5c-b007-ece7b5f42d7b');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-1e21c21f-e10e-4393-a3a9-a9674222f5ae\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-1e21c21f-e10e-4393-a3a9-a9674222f5ae')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-1e21c21f-e10e-4393-a3a9-a9674222f5ae button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"print(\\\"\\\\n Monitoring stopped\",\n  \"rows\": 10,\n  \"fields\": [\n    {\n      \"column\": \"Temp\",\n      \"properties\": {\n        \"dtype\": \"float32\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          17.200000762939453,\n          14.199999809265137,\n          27.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Power\",\n      \"properties\": {\n        \"dtype\": \"float32\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          1696.8067626953125,\n          1925.584716796875,\n          1530.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"TV\",\n      \"properties\": {\n        \"dtype\": \"int32\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Dryer\",\n      \"properties\": {\n        \"dtype\": \"int32\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Oven\",\n      \"properties\": {\n        \"dtype\": \"int32\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Fridge\",\n      \"properties\": {\n        \"dtype\": \"int32\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Micro\",\n      \"properties\": {\n        \"dtype\": \"int32\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Monitoring stopped.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query.stop()"
      ],
      "metadata": {
        "id": "7zQXMDBESW5x"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "z-FLIKMngpkK"
      },
      "execution_count": 6,
      "outputs": []
    }
  ]
}